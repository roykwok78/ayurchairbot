import os, json, re, time, datetime
import requests
from bs4 import BeautifulSoup

# -------- å¯èª¿åƒæ•¸ï¼ˆäº¦å¯ç”¨ GitHub Secrets è¦†è“‹ï¼‰ --------
SEARCH_URL = os.getenv("SEARCH_URL") or "https://jp.mercari.com/zh-TW/search?keyword=ayur%20chair&order=desc&sort=created_time&status=on_sale"
KEYWORDS = [s.strip().lower() for s in os.getenv("KEYWORDS", "ayur chair").split(",") if s.strip()]
COLOR_KEYWORDS = [s.strip().lower() for s in os.getenv("COLOR_KEYWORDS", "").split(",") if s.strip()]
MIN_PRICE = int(os.getenv("MIN_PRICE") or "0")
MAX_PRICE = int(os.getenv("MAX_PRICE") or "0")
LATEST_COUNT = int(os.getenv("LATEST_COUNT") or "5")
ALWAYS_SEND_LATEST = os.getenv("ALWAYS_SEND_LATEST") == "1"
SEEN_FILE = "data/seen_ids.json"

TG_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TG_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")

HEADERS = {
    "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0 Safari/537.36",
    "Accept-Language": "zh-TW,zh;q=0.9,en;q=0.8,ja;q=0.7",
}

PRICE_RE = re.compile(r"[ï¿¥Â¥]\s*([\d,]+)")

# -------- é€šç”¨å·¥å…· --------
def load_seen():
    try:
        with open(SEEN_FILE, "r", encoding="utf-8") as f:
            return set(json.load(f))
    except Exception:
        return set()

def save_seen(seen):
    os.makedirs(os.path.dirname(SEEN_FILE), exist_ok=True)
    with open(SEEN_FILE, "w", encoding="utf-8") as f:
        json.dump(sorted(list(seen)), f, ensure_ascii=False)

def send_telegram(text: str):
    if not TG_TOKEN or not TG_CHAT_ID:
        print("WARN: Telegram æœªè¨­å®šï¼Œç•¥éæ¨é€")
        return
    url = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
    try:
        r = requests.post(
            url,
            json={"chat_id": TG_CHAT_ID, "text": text, "disable_web_page_preview": True},
            timeout=20,
        )
        if r.status_code != 200:
            print(f"WARN: Telegram å›æ‡‰ {r.status_code} {r.text[:200]}")
    except Exception as e:
        print(f"WARN: Telegram æ¨é€å¤±æ•—: {e}")

def parse_price(text: str) -> int:
    m = PRICE_RE.search(text.replace(",", ""))
    if m:
        try:
            return int(m.group(1).replace(",", ""))
        except Exception:
            return 0
    nums = re.findall(r"\d+", text)
    return int(nums[0]) if nums else 0

def match_filters(title: str, price: int) -> bool:
    t = (title or "").lower()
    if KEYWORDS and not any(k in t for k in KEYWORDS):
        return False
    if COLOR_KEYWORDS and COLOR_KEYWORDS and not any(c in t for c in COLOR_KEYWORDS):
        return False
    if MIN_PRICE and price < MIN_PRICE:
        return False
    if MAX_PRICE and MAX_PRICE > 0 and price > MAX_PRICE:
        return False
    return True

# -------- æŠ“å–åˆ—è¡¨ï¼ˆæ›´ç©©é™£åšæ³•ï¼‰--------
def fetch_list():
    r = requests.get(SEARCH_URL, headers=HEADERS, timeout=30)
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "html.parser")

    # å–æ‰€æœ‰å•†å“å¡ anchorï¼šhref ä»¥ /item/m é–‹é ­
    anchors = soup.select('a[href^="/item/m"]')
    items = []
    seen_ids_local = set()

    for a in anchors:
        href = a.get("href") or ""
        if not href.startswith("/item/m"):
            continue
        item_id = href.rsplit("/", 1)[-1]
        if item_id in seen_ids_local:
            continue
        seen_ids_local.add(item_id)
        url = "https://jp.mercari.com" + href

        # å˜—è©¦åœ¨å¡ç‰‡é™„è¿‘æ‰¾æ¨™é¡Œ/åƒ¹éŒ¢
        title = None
        price = 0

        # 1) å…ˆè©¦ <img alt>
        img = a.find("img")
        if img and img.get("alt"):
            title = img["alt"].strip()

        # 2) å†è©¦ anchor åŠçˆ¶å±¤æ–‡æœ¬
        card = a
        for _ in range(3):  # å¾€ä¸Šæ‰¾å¹¾å±¤
            text_block = (card.get_text(" ", strip=True) or "")
            if not title:
                # æ‰¾ä¸€æ®µåƒæ¨™é¡Œçš„å­—
                for tag in card.find_all(["p", "div", "span"], limit=8):
                    t = (tag.get_text(" ", strip=True) or "").strip()
                    if 6 <= len(t) <= 120 and "ï¿¥" not in t and "Â¥" not in t:
                        title = t
                        break
            if price == 0:
                price = parse_price(text_block)
            if title and price:
                break
            if card.parent:
                card = card.parent
            else:
                break

        # 3) å¾Œå‚™ï¼šè‡³å°‘çµ¦å€‹ title
        if not title:
            title = "ayur chair"

        items.append({"id": item_id, "title": title, "price": price, "url": url})

    print(f"DEBUG: åˆ—è¡¨æŠ“åˆ° {len(items)} ä»¶")
    return items

# -------- æŠ“è©³æƒ…é å–ä¸Šæ¶æ™‚é–“ï¼ˆJSTï¼‰--------
def fetch_date(item_url: str) -> str:
    try:
        r = requests.get(item_url, headers=HEADERS, timeout=30)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")

        # å¸¸è¦‹ metaï¼šog:updated_time / product:price:updated_time / article:modified_time
        for key in ("og:updated_time", "product:price:updated_time", "article:modified_time", "og:published_time"):
            meta = soup.find("meta", attrs={"property": key})
            if meta and meta.get("content"):
                iso = meta["content"].strip().replace("Z", "+00:00")
                dt_utc = datetime.datetime.fromisoformat(iso)
                jst = dt_utc.astimezone(datetime.timezone(datetime.timedelta(hours=9)))
                return jst.strftime("%Y-%m-%d %H:%M")
    except Exception as e:
        print(f"WARN: å–ä¸Šæ¶æ™‚é–“å¤±æ•—: {e}")
    return ""

def format_item(it, with_date=False) -> str:
    date_str = ""
    if with_date:
        dt = fetch_date(it["url"])
        if dt:
            date_str = f"\nä¸Šæ¶ï¼š{dt}"
    price_part = f" Â¥{it['price']:,}" if it["price"] else ""
    return f"{it['title']}{price_part}{date_str}\n{it['url']}"

# -------- ä¸»æµç¨‹ --------
def main():
    # Debug ping
    send_telegram("ğŸ“¡ Mercari Watch æ¸¬è©¦è¨Šæ¯ï¼šworkflow å·²å•Ÿå‹•")
    print(f"DEBUG: ALWAYS_SEND_LATEST={ALWAYS_SEND_LATEST}, LATEST_COUNT={LATEST_COUNT}")
    print(f"DEBUG: SEARCH_URL={SEARCH_URL}")

    seen = load_seen()
    items = fetch_list()

    # æ–°è²¨ï¼ˆæŒ‰ç›®å‰é é¢é †åº = å·²ç”±æ–°è‡³èˆŠï¼‰
    new_items = [it for it in items if it["id"] not in seen and match_filters(it["title"], it["price"])]
    print(f"DEBUG: new_items={len(new_items)} / seen_ids={len(seen)}")

    messages = []

    # æœ‰æ–°è²¨ â†’ æ¨é€æ–°è²¨
    if new_items:
        msg = "ğŸ†• Mercari æ–°ä¸Šæ¶ ayur chairï¼ˆåœ¨å”®ï¼‰\n\n"
        for i, it in enumerate(new_items, 1):
            msg += f"{i}. {format_item(it, with_date=True)}\n\n"
        messages.append(msg.strip())

    # éœ€è¦æ¯æ¬¡éƒ½æ¨æœ€æ–° N å€‹
    if ALWAYS_SEND_LATEST:
        latest = items[:LATEST_COUNT]
        print(f"DEBUG: latest_to_send={len(latest)}")
        if latest:
            msg2 = f"ğŸ“Œ æœ€æ–° {len(latest)} å€‹åœ¨å”® ayur chairï¼ˆç”±æ–°è‡³èˆŠï¼‰\n\n"
            for i, it in enumerate(latest, 1):
                msg2 += f"{i}. {format_item(it, with_date=True)}\n\n"
            messages.append(msg2.strip())
        else:
            messages.append("ğŸ“Œ æœ€æ–°æ¸…å–®ï¼šç›®å‰æœå°‹çµæœæ²’æœ‰åœ¨å”®å•†å“ã€‚")

    # æ›´æ–° seenï¼ˆåªæŠŠçœŸæ­£è¦–ç‚ºæ–°è²¨çš„åŠ å…¥ï¼‰
    for it in new_items:
        seen.add(it["id"])
    save_seen(seen)

    # ç™¼é€
    if not messages:
        print("INFO: ç„¡æ–°è²¨ï¼Œä¸”æœªé–‹ ALWAYS_SEND_LATESTï¼›ä»Šæ¬¡ä¸æ¨é€åˆ—è¡¨ã€‚")
    else:
        for m in messages:
            send_telegram(m)

    print(f"Done. Pushed new={len(new_items)}, sent_latest={ALWAYS_SEND_LATEST}")

if __name__ == "__main__":
    time.sleep(1)
    main()
